[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tarea_1",
    "section": "",
    "text": "Tarea 1\n\nEjercicio 1.- Explique ¿Por qué el aprendizaje reforzado se diferencia del aprendizaje supervisado y del no supervisado?\nEl aprendizaje reforzado se distingue por ser un método de aprendizaje que considera las investigaciones tipo prueba y error; y las recompensas retrasadas. Lo que hace que este método se ha más adecuado para los problemas interactivos en comparación con el aprendizaje supervisado y no supervisado. Lo anterior se debe a la dificultad que tienen los problemas interactivos al momento de generar muestras de datos que sean tanto correctos como representativos de todas las situaciones en las que el agente debe actuar. Las muestras de datos son necesarias para que los aprendizaje supervisado y no supervisado puedan ser utilizados.\n\n\nEjercicio 2.- De acuerdo al video de Steve Brunton, explique cuál es el significado de la siguiente expresión:\n\\[ V_{\\pi}(s)=E {\\LARGE(} \\sum_{t} \\gamma^{t}r_{t}|s_{0}=s{\\LARGE)} \\]\n\\(V_{\\pi}(s)\\) nos permite medir la recompensa esperada en el futuro si empiezo en el estado \\(s\\) y usando la política \\(\\pi\\). Esto quiere decir que para saber si nuestra política es buena o mala, se tienen que observar que tal buen valor se tiene en ese estado.\nUn ejemplo puede ser en una partida de Blackjack si mis primas dos cartas junto 20 pts, y mis compañeros sus cartas expuestas están en el rango 6-9 pts. Yo probablemente tenga una mejor oportunidad de ganar. Ya que mis compañeros tienen más chance de pasarse de puntos.\n\n\nEjercicio 3.- Hacer una linea del tiempo desde 1950 hasta 2012.\n\n\nEjercicio 4.- Considerando el siguiente problema de consumo y ahorro con dinamica:\n\\[\nX_{k+1}=(1-r)(x_{k}-a_{k}) \\text{ k=0,1,...,N-1}\n\\]\ny la funcion de utilidad como\n\\[\n\\beta^{N}(X_{N})^{1-\\gamma}+\\sum_{k=0}^{N-1}\\beta^{k}(a_{k})^{1-\\gamma}.\n\\]\nDemuestre que la función de valor de DP algoritmo de la forma:\n\\[J_{k}(x)=A_{k}k\\beta^{k}x^{1-\\gamma},\\]\ndonde \\(A_{N}=1\\) y para \\(k=N-1,…,0\\)\n\\[A_{k}={\\LARGE [}1+((1+r)\\beta A_{k+1})^{1/\\gamma}{\\LARGE}]^{\\gamma}\\]\nDemostrar tambien que la politica optima es \\(h_{k}(x)=A^{-1/\\gamma}x,\\)   #####Demotración: Siguiendo el algoritmo de la programación dinámica se sigue que para este caso particular \\(J_{N}(x)=\\beta^{N}(x_N)^{1-\\gamma}\\)\nluego, para \\(k= N-1\\) \\[J_{N-1}=\\min_{a\\in A(x)}\\{\\beta^{N-1}(a)^{1-\\gamma} + \\beta^{N}(1+r)^{1-\\gamma}(x-a)^{1-\\gamma}\\}\\] derivando con respecto a \\(a\\) obtenemos \\[(1-\\gamma)\\beta^{N-1}a^{-\\gamma}- \\beta^{N}(1+r)^{1-\\gamma}(x-a)^{-\\gamma}\\]} depués igualando a cero \\[(1-\\gamma)\\beta^{N-1}a^{-\\gamma}-\\beta(1+r)^{1-\\gamma}(x-a)^{-\\gamma}=0\\] entonces \\[(\\cfrac{x-a}{a})^\\gamma=\\beta(1+r)^{1-\\gamma}\\] \\[\\cfrac{x-a}{a}=[\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\] \\[a=\\dfrac{x}{[\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}+1}\\] \\[J_{N-1}(x)=\\beta^{N-1}(a_0)^{1-\\gamma}+\\beta^N(1+r)^{1-\\gamma}(x-a_0)^{1-\\gamma}\\] \\[J_{N-1}(x)=\\dfrac{\\beta^{N-1}x^{1-\\gamma}}{([\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}+1)^{1-\\gamma}}+\\beta^N(1+r)^{1-\\gamma}\\left[\\dfrac{x[\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}}{\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}+1}\\right]^{1-\\gamma}\\] \\[J_{N-1}(x)=\\beta^{N-1}x^{1-\\gamma}\\left[[\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}+1\\right]^{\\gamma}\\] \\[J_{N-1}(x)=A_{N-1}\\beta^{N-1}x^{1-\\gamma}\\] \\[A_{N-1}=\\left(1+((1+r)^{1-\\gamma}\\beta)^{\\frac{1}{\\gamma}}\\right)^{\\gamma}\\] Supongamos que se cumple para \\(n=k+1\\), entonces \\(J_{k+1}(x)=A_{k+1}\\beta^{k+1}x^{1-\\gamma}\\). Ahora \\[J_k(x)=\\min_{0&lt;a&lt;x}\\left\\{\\beta^ka^{1-\\gamma}+A_{k+1}\\beta^{k+1}(1+r)^{1-\\gamma}(x-a)^{1-\\gamma} \\right\\}\\] Derivando e igualando a 0 para encontrar el mínimo \\[(1-\\gamma)\\beta^ka^{-\\gamma}-A_{k+1}\\beta^{k+1}(1+\\gamma)^{1-\\gamma}(1-\\gamma)(x-a)^{-\\gamma}=0\\] Veamos que \\[(1-\\gamma)\\beta^k\\left[ a^{-\\gamma}-A_{k+1}\\beta(1+r)^{1-\\gamma}(x-a)^{-\\gamma}  \\right]=0\\] \\[a^{-\\gamma}-A_{k+1}\\beta(1+r)^{1-\\gamma}(x-a)^{-\\gamma}=0\\] Despejando \\(a\\) \\[\\left(\\dfrac{x-a}{a}\\right)^{\\gamma}=A_{k+1}\\beta(1+\\gamma)^{1-\\gamma}\\] \\[a=\\dfrac{x}{\\left[ A_{k+1}\\beta(1+r)^{1-\\gamma}  \\right]^{\\frac{1}{\\gamma}}+1}\\] A este punto lo renombramos como \\(a_0\\) y sustituimos \\[J_k(x)=\\dfrac{\\beta^kx^{1-\\gamma}}{\\left[\\left[ A_{k+1}\\beta(1+r)^{1-\\gamma}  \\right]^{\\frac{1}{\\gamma}}+1\\right]^{1-\\gamma}}+\\dfrac{A_{k+1}\\beta^{k+1}(1+r)^{1-\\gamma}\\left(x[A_{k+1}\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}}{\\left[\\left[ A_{k+1}\\beta(1+r)^{1-\\gamma}  \\right]^{\\frac{1}{\\gamma}}+1\\right]^{1-\\gamma}}\\] Desarrollando y reacomodando términos llegamos a \\[\\dfrac{\\beta^kx^{1-\\gamma}\\left( 1+[A_{k+1}\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}  \\right)}{\\left(1+[A_{k+1}\\beta(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}  \\right)^{1-\\gamma}}=\\beta^kx^{1-\\gamma}A_k\\] ## 5 \\[cx^{1-\\gamma}=\\min\\left\\{ a^{1-\\gamma}+\\beta c(1+r)^{1-\\gamma}(x-a)^{1-\\gamma} \\right\\}\\] Derivando respecto a \\(a\\) e igualando a 0 \\[(1-\\gamma)a^{-\\gamma}-\\beta c(1+r)^{1-\\gamma}(1-\\gamma)(x-a)^{-\\gamma}=0\\] \\[(1-\\gamma)\\left[ a^{-\\gamma}-\\beta c(1+r)^{1-\\gamma}(x-a)^{-\\gamma}\\right]=0\\] \\[a^{-\\gamma}-\\beta c(1+r)^{1-\\gamma}(x-a)^{-\\gamma}=0\\] Despenjando \\(a\\) \\[\\left(\\dfrac{x-a}{a}\\right)^{\\gamma}=\\beta c(1+r)^{1-\\gamma}\\] \\[x=a\\left[\\beta c(1+r)^{1-\\gamma} \\right]^{\\frac{1}{\\gamma}}+a\\] \\[a_0=a=\\dfrac{x}{\\left[\\beta c(1+r)^{1-\\gamma} \\right]^{\\frac{1}{\\gamma}}+1}\\] Sustituyendo \\(a_0\\), así \\[cx^{1-\\gamma}=\\dfrac{x^{1-\\gamma}+\\beta c(1+r)^{1-\\gamma}x^{1-\\gamma}\\left[ (\\beta c (1+r)^{1-\\gamma})^{\\frac{1}{\\gamma}} \\right]^{1-\\gamma}}{\\left[ (\\beta c (1+r)^{1-\\gamma})^{\\frac{1}{\\gamma}} +1\\right]^{1-\\gamma}}\\] \\[cx^{1-\\gamma}=x^{1-\\gamma}\\left[1+[\\beta c (1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\right]^{\\gamma}\\] entonces \\[cx^{1-\\gamma}=x^{1-\\gamma}\\left[1+[\\beta c(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\right]^{\\gamma}\\] \\[c=\\left[1+[\\beta c(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\right]^{\\gamma}\\] \\[c^{\\frac{1}{\\gamma}}=1+[\\beta c(1+r)^{1-\\gamma}]^{\\frac{1}{\\gamma}}\\] \\[c^{\\frac{1}{\\gamma}}=\\left[1-\\beta^{\\frac{1}{\\gamma}}(1+r)^{\\frac{1-\\gamma}{\\gamma}}\\right]\\] \\[c^{\\frac{1}{\\gamma}}=\\dfrac{1}{1-\\beta^{\\frac{1}{\\gamma}}(1+r)^{\\frac{1-\\gamma}{\\gamma}}}\\]",
    "crumbs": [
      "Tarea 1"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]